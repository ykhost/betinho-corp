{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808fdd40-c85f-452b-97c1-d52133dcb9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('User Raw to Trusted') \\\n",
    "    .config('spark.sql.extensions','io.delta.sql.DeltaSparkSessionExtension') \\\n",
    "    .config('spark.sql.catalog.spark_catalog','org.apache.spark.sql.delta.catalog.DeltaCatalog') \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/opt/hive/data/warehouse\") \\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "993ac8b1-2c88-40c6-b4f8-3d699104fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "posicao_veiculo = 's3a://raw/posicao_veiculo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e54798-e31f-45cb-908f-f6aa3a9bbdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_parada = spark.read.json(parada)\n",
    "df_posicao_veiculo = spark.read.json(posicao_veiculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89fddca9-6122-4a45-a3e3-d39ef098fe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hr: string (nullable = true)\n",
      " |-- l: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- c: string (nullable = true)\n",
      " |    |    |-- cl: long (nullable = true)\n",
      " |    |    |-- lt0: string (nullable = true)\n",
      " |    |    |-- lt1: string (nullable = true)\n",
      " |    |    |-- qv: long (nullable = true)\n",
      " |    |    |-- sl: long (nullable = true)\n",
      " |    |    |-- vs: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- a: boolean (nullable = true)\n",
      " |    |    |    |    |-- is: string (nullable = true)\n",
      " |    |    |    |    |-- p: long (nullable = true)\n",
      " |    |    |    |    |-- px: double (nullable = true)\n",
      " |    |    |    |    |-- py: double (nullable = true)\n",
      " |    |    |    |    |-- sv: string (nullable = true)\n",
      " |    |    |    |    |-- ta: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_posicao_veiculo.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c9f77d8-ce4d-41aa-bcba-054170a85c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "df_posicao_veiculo2 = df_posicao_veiculo.withColumn(\"dict\", explode(col('l')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dadc7f-fcc0-4627-aeeb-703bb6b33451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posicao_veiculo2.select(\"dict\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f8d2756-2dda-420a-86da-0852b57e0229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hr: string (nullable = true)\n",
      " |-- l: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- c: string (nullable = true)\n",
      " |    |    |-- cl: long (nullable = true)\n",
      " |    |    |-- lt0: string (nullable = true)\n",
      " |    |    |-- lt1: string (nullable = true)\n",
      " |    |    |-- qv: long (nullable = true)\n",
      " |    |    |-- sl: long (nullable = true)\n",
      " |    |    |-- vs: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- a: boolean (nullable = true)\n",
      " |    |    |    |    |-- is: string (nullable = true)\n",
      " |    |    |    |    |-- p: long (nullable = true)\n",
      " |    |    |    |    |-- px: double (nullable = true)\n",
      " |    |    |    |    |-- py: double (nullable = true)\n",
      " |    |    |    |    |-- sv: string (nullable = true)\n",
      " |    |    |    |    |-- ta: string (nullable = true)\n",
      " |-- dict: struct (nullable = true)\n",
      " |    |-- c: string (nullable = true)\n",
      " |    |-- cl: long (nullable = true)\n",
      " |    |-- lt0: string (nullable = true)\n",
      " |    |-- lt1: string (nullable = true)\n",
      " |    |-- qv: long (nullable = true)\n",
      " |    |-- sl: long (nullable = true)\n",
      " |    |-- vs: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- a: boolean (nullable = true)\n",
      " |    |    |    |-- is: string (nullable = true)\n",
      " |    |    |    |-- p: long (nullable = true)\n",
      " |    |    |    |-- px: double (nullable = true)\n",
      " |    |    |    |-- py: double (nullable = true)\n",
      " |    |    |    |-- sv: string (nullable = true)\n",
      " |    |    |    |-- ta: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_posicao_veiculo2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3a395f8-195e-4afb-b681-8ee8a6fe272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posicao_veiculo3 = df_posicao_veiculo2.select(\n",
    "    col(\"dict.c\").alias(\"LETREIRO_LINHA\"), \n",
    "    col(\"dict.cl\").alias(\"ID_LINHA\"), \n",
    "    col(\"dict.lt0\").alias(\"LETREIRO_DESTINO_LINHA\"), \n",
    "    col(\"dict.lt1\").alias(\"LETREIRO_ORIGEM_LINHA\"), \n",
    "    col(\"dict.qv\").alias(\"QTD_VEICULO_LINHA\"), \n",
    "    col(\"dict.sl\").alias(\"SENTIDO_O_LINHA\"), \n",
    "    explode(\"dict.vs\").alias(\"veiculos\"),\n",
    "    col(\"veiculos.a\").alias(\"ACESSIVEL_VEICULO\"),\n",
    "    col(\"veiculos.p\").alias(\"ID_VEICULO\"),\n",
    "    col(\"veiculos.px\").alias(\"LONGITUDE_VEICULO\"),\n",
    "    col(\"veiculos.py\").alias(\"LATITUDE_VEICULO\")\n",
    ").drop(\"veiculos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a968d62-4462-47f5-a2fb-e7d9d257e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posicao_veiculo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "482d881f-c367-49bb-be76-5778186d23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_path_posicao_veiculo = 's3a://trusted/posicao_veiculo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ed90dc-67b3-4274-a7f4-4195bf20c3ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_posicao_veiculo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_posicao_veiculo\u001b[49m\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m'\u001b[39m)\\\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;241m.\u001b[39mmode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwriteSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msave(silver_path_posicao_veiculo)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_posicao_veiculo' is not defined"
     ]
    }
   ],
   "source": [
    "df_posicao_veiculo.write.format('delta')\\\n",
    "    .mode('overwrite').option(\"overwriteSchema\", \"true\").save(silver_path_posicao_veiculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c93b656c-b503-457c-a19b-845e0d3da2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posicao_to_previsao = spark.read.format('delta') \\\n",
    "  .load(silver_path_posicao_veiculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef517904-d63f-4f7d-b335-345252081cf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSHOW DATABASES\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1034\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     sqlQuery \u001b[38;5;241m=\u001b[39m formatter\u001b[38;5;241m.\u001b[39mformat(sqlQuery, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "635f21c1-5f4f-4629-b569-e0ee9af05055",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE DATABASE SPTRANS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1034\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     sqlQuery \u001b[38;5;241m=\u001b[39m formatter\u001b[38;5;241m.\u001b[39mformat(sqlQuery, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE SPTRANS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db84be5-2072-4f68-8aa7-dd2bb3764510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posicao_to_previsao.saveAsTable(\"SPTRANS.POSICAO_VEICULO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c47ce03-caf2-4209-9ec4-332173bddac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, explode, lit\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, StringType, IntegerType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dee5be-8e03-4272-bc14-1fb3401f94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://api.olhovivo.sptrans.com.br/v2.1/Login/Autenticar?token=d3f026bb74699c88e75ef5a7e71cf1181e70cd26cb93b8b31038c9df15ba2f61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf70c6e-bfa8-4e85-a49c-92c21e2b0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.sql import Row\n",
    "import json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, IntegerType, BooleanType, TimestampType, FloatType\n",
    "\n",
    "url = \"http://api.olhovivo.sptrans.com.br/v2.1/Login/Autenticar?token=d3f026bb74699c88e75ef5a7e71cf1181e70cd26cb93b8b31038c9df15ba2f61\"\n",
    "response = requests.post(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "  cookies = response.cookies\n",
    "  # Assuming you want to fetch data from another endpoint using the authentication cookie\n",
    "  api_endpoint = \"http://api.olhovivo.sptrans.com.br/v2.1/posicao\"  # Replace with the desired endpoint\n",
    "  response_api = requests.get(api_endpoint, cookies=cookies)\n",
    "\n",
    "  if response_api.status_code == 200:\n",
    "    data = response_api.json()  # Convert JSON to a list of Rows\n",
    "    print(data)\n",
    "    df = spark.createDataFrame(data, schema=schema)\n",
    "    df.show()\n",
    "  else:\n",
    "    print(f\"Error fetching data from API: {response_api.status_code}\")\n",
    "else:\n",
    "  print(f\"Error authenticating: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dafd3922-2b45-4142-843a-4dd8cd3dd38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.sql.functions import udf\n",
    "from http.cookiejar import LWPCookieJar\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "post_auth = \"http://api.olhovivo.sptrans.com.br/v2.1/Login/Autenticar?token=d3f026bb74699c88e75ef5a7e71cf1181e70cd26cb93b8b31038c9df15ba2f61\"\n",
    "session = requests.Session()\n",
    "session.post(post_auth)\n",
    "\n",
    "def fetch_data(id_linha):\n",
    "    url = \"http://api.olhovivo.sptrans.com.br/v2.1/Login/Autenticar?token=d3f026bb74699c88e75ef5a7e71cf1181e70cd26cb93b8b31038c9df15ba2f61\"\n",
    "    session = requests.Session()\n",
    "    response = session.post(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        cookies = response.cookies\n",
    "        \n",
    "        endpoint = \"http://api.olhovivo.sptrans.com.br/v2.1/Previsao/Linha?\"\n",
    "        params = {\n",
    "            \"codigoLinha\": id_linha,\n",
    "        }\n",
    "        response = session.get(endpoint, params=params, cookies=cookies)\n",
    "\n",
    "        time = datetime.datetime.now()\n",
    "        bucket = \"raw\"\n",
    "        name_file = f\"previsao_chegada_{time}.json\"\n",
    "        caminho_de_salvar = f\"/previsao_chegada/{name_file}\"\n",
    "\n",
    "        upload_json_to_minio(\n",
    "            data=response.json(), \n",
    "            bucket=bucket, \n",
    "            object_name=name_file, \n",
    "            path_save=caminho_de_salvar\n",
    "        )\n",
    "        return True  # assuming API returns a list of records\n",
    "    else:\n",
    "        print(\"NAODEUCERTO\")\n",
    "\n",
    "convertUDF = udf(lambda id: fetch_data(id))\n",
    "\n",
    "df_previsao_responde = df_posicao_to_previsao.withColumn(\"response\", convertUDF(col(\"id_linha\"))).select(\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0af039d1-f643-4842-8343-bc8da7743e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_previsao_responde\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:606\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a bool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_previsao_responde.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e220e216-f4c0-4be8-983e-b28da9cec943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from io import BytesIO\n",
    "\n",
    "def upload_json_to_minio(data, bucket, object_name, path_save):\n",
    "    # Configurar o cliente boto3 para MinIO\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        endpoint_url='http://minio:9000',  # Altere para o endpoint do seu MinIO\n",
    "        aws_access_key_id='datalake',        # Altere para sua chave de acesso do MinIO\n",
    "        aws_secret_access_key='datalake',    # Altere para sua chave secreta do MinIO\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        print(\"Serializar o conteúdo JSON e convertê-lo para bytes\")\n",
    "        json_bytes = json.dumps(data).encode('utf-8')\n",
    "\n",
    "        print(\"Criar um buffer de bytes para simular um arquivo\")\n",
    "        json_buffer = BytesIO(json_bytes)\n",
    "\n",
    "        # Upload do \"arquivo\" JSON para o MinIO\n",
    "        s3_client.upload_fileobj(\n",
    "            json_buffer,\n",
    "            bucket,\n",
    "            path_save\n",
    "         )\n",
    "        print(f'Arquivo JSON foi carregado com sucesso no bucket {bucket}, objeto: {object_name}')\n",
    "    \n",
    "    except NoCredentialsError:\n",
    "        print(\"Credenciais não encontradas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e4a06fc-4979-4c6c-a361-36a3cf5c131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path_posicao_veiculo = 's3a://raw/previsao_chegada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ec5d793-0e70-49b3-937a-a24f3a9a621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posicao_veiculo = spark.read.json(raw_path_posicao_veiculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e436c301-b2cd-48c1-aea6-ede861ae1fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hr: string (nullable = true)\n",
      " |-- ps: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- cp: long (nullable = true)\n",
      " |    |    |-- np: string (nullable = true)\n",
      " |    |    |-- px: double (nullable = true)\n",
      " |    |    |-- py: double (nullable = true)\n",
      " |    |    |-- vs: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- a: boolean (nullable = true)\n",
      " |    |    |    |    |-- is: string (nullable = true)\n",
      " |    |    |    |    |-- p: string (nullable = true)\n",
      " |    |    |    |    |-- px: double (nullable = true)\n",
      " |    |    |    |    |-- py: double (nullable = true)\n",
      " |    |    |    |    |-- sv: string (nullable = true)\n",
      " |    |    |    |    |-- t: string (nullable = true)\n",
      " |    |    |    |    |-- ta: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_posicao_to_previsao.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a234b114-b51e-45d0-b255-49a2f449c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode = df_posicao_to_previsao.withColumn(\"ps_explod\", explode(\"ps\"))\\\n",
    "    .withColumn(\"vs_explod\", explode(\"ps_explod.vs\")).select(\"ps_explod\",\"vs_explod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "039846a1-6ecc-4855-b116-694a044b2acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ps_explod: struct (nullable = true)\n",
      " |    |-- cp: long (nullable = true)\n",
      " |    |-- np: string (nullable = true)\n",
      " |    |-- px: double (nullable = true)\n",
      " |    |-- py: double (nullable = true)\n",
      " |    |-- vs: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- a: boolean (nullable = true)\n",
      " |    |    |    |-- is: string (nullable = true)\n",
      " |    |    |    |-- p: string (nullable = true)\n",
      " |    |    |    |-- px: double (nullable = true)\n",
      " |    |    |    |-- py: double (nullable = true)\n",
      " |    |    |    |-- sv: string (nullable = true)\n",
      " |    |    |    |-- t: string (nullable = true)\n",
      " |    |    |    |-- ta: string (nullable = true)\n",
      " |-- vs_explod: struct (nullable = true)\n",
      " |    |-- a: boolean (nullable = true)\n",
      " |    |-- is: string (nullable = true)\n",
      " |    |-- p: string (nullable = true)\n",
      " |    |-- px: double (nullable = true)\n",
      " |    |-- py: double (nullable = true)\n",
      " |    |-- sv: string (nullable = true)\n",
      " |    |-- t: string (nullable = true)\n",
      " |    |-- ta: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_explode.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b1055659-fc3f-4772-96c4-18f12bc00e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prev_chegada = df_explode.select(\n",
    "    col(\"ps_explod.cp\").alias(\"ID_PARADA\"), \n",
    "    col(\"ps_explod.np\").alias(\"nome_parada\"),\n",
    "    col(\"ps_explod.px\").alias(\"latitude_loc\"), \n",
    "    col(\"ps_explod.py\").alias(\"longtitude\"),\n",
    "    col(\"vs_explod.a\").alias(\"VEICULO_ACESSIVEL\"),\n",
    "    col(\"vs_explod.is\").alias(\"TIMESTAMP\"),\n",
    "    col(\"vs_explod.p\").alias(\"PREFIXO_VEICULO\"),\n",
    "    col(\"vs_explod.px\").alias(\"LATITUDE_VEICULO\"),\n",
    "    col(\"vs_explod.py\").alias(\"LONGITUDE_VEICULO\"),\n",
    "    col(\"vs_explod.t\").alias(\"HORARIO_PREVISTO_CHEADA\")    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3e4dc871-d384-4be6-aaa6-73d10f045033",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_path_posicao_veiculo = 's3a://silver/previsao_chegada'\n",
    "df_prev_chegada.write.format('delta')\\\n",
    "    .mode('overwrite').option(\"overwriteSchema\", \"true\").save(silver_path_posicao_veiculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d1c411d6-5502-48ea-a385-e56a5ca641da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+----------+\n",
      "|       cp|  np|        px|        py|\n",
      "+---------+----+----------+----------+\n",
      "|760012111|null|-46.435489|-23.495062|\n",
      "|760002802|null|-46.443393|-23.509101|\n",
      "|600005464|null|-46.527918|-23.528948|\n",
      "|350002423|    |-46.387067|-23.508035|\n",
      "|350002420|    |-46.388636|-23.506043|\n",
      "|350002425|    | -46.38536|-23.510288|\n",
      "|350002427|    |-46.383354|-23.511908|\n",
      "|350002451|    |-46.397659|-23.501721|\n",
      "|350002410|    |-46.400176|-23.498273|\n",
      "|350002416|    |-46.393306|-23.500041|\n",
      "|  3511854|    |-46.393636|-23.500189|\n",
      "|860012107|    |-46.414106|-23.494477|\n",
      "|860012108|    |-46.420331|-23.493976|\n",
      "|860012106|    |-46.411507| -23.49483|\n",
      "|860012105|    |-46.408131|-23.494799|\n",
      "|760012110|    |-46.431702|-23.495227|\n",
      "|860012124|    |-46.422071|-23.494154|\n",
      "|860012109|    |-46.426964|-23.494623|\n",
      "|760002790|    |-46.443165|-23.494625|\n",
      "|760002793|    |-46.442241|-23.497567|\n",
      "+---------+----+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_explode_ps.select(\"ps_explod.cp\",\"ps_explod.np\", \"ps_explod.px\", \"ps_explod.py\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7b4b4a4f-1998-442f-ab9b-a80a63476c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_path_previsao_veiculo = 's3a://silver/previsao_chegada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a7e808c6-c90d-4223-99ba-0c6d9f5c7a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previsao_veiculo = spark.read.format('delta') \\\n",
    "  .load(silver_path_previsao_veiculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "45ae5261-431f-4c55-b613-712ac0249940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold_diff = df_previsao_veiculo.filter(\"PREFIXO_VEICULO=11523\").distinct().sort(col(\"HORARIO_PREVISTO_CHEADA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f4003c5f-c379-47c3-93ef-79c3edf4af95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID_PARADA',\n",
       " 'nome_parada',\n",
       " 'latitude_loc',\n",
       " 'longtitude',\n",
       " 'VEICULO_ACESSIVEL',\n",
       " 'TIMESTAMP',\n",
       " 'PREFIXO_VEICULO',\n",
       " 'LONGITUDE_VEICULO',\n",
       " 'LATITUDE_VEICULO',\n",
       " 'HORARIO_PREVISTO_CHEADA']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gold_diff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9c8cd7df-8435-45ee-b75a-0f68079dd1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Raio da Terra em quilômetros\n",
    "    R = 6371.0\n",
    "\n",
    "    # Converter graus para radianos\n",
    "    lat1 = math.radians(lat1)\n",
    "    lon1 = math.radians(lon1)\n",
    "    lat2 = math.radians(lat2)\n",
    "    lon2 = math.radians(lon2)\n",
    "\n",
    "    # Diferenças entre os pontos\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    # Fórmula de Haversine\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    # Distância\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "calc_km_long_lat = udf(lambda lat1, lon1, lat2, lon2: haversine(lat1, lon1, lat2, lon2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3cc3d30e-16ac-4d5f-b558-57c84b6b6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, radians, sin, cos, atan2, sqrt\n",
    "from pyspark.sql.types import DoubleType\n",
    "R = 6371.0\n",
    "\n",
    "# Converter as colunas de latitude e longitude para radianos\n",
    "df = df_gold_diff.withColumn(\"lat1_rad\", radians(col(\"latitude_loc\"))) \\\n",
    "       .withColumn(\"lon1_rad\", radians(col(\"longtitude\"))) \\\n",
    "       .withColumn(\"lat2_rad\", radians(col(\"LATITUDE_VEICULO\"))) \\\n",
    "       .withColumn(\"lon2_rad\", radians(col(\"LONGITUDE_VEICULO\")))\n",
    "\n",
    "# Calcular a diferença entre as coordenadas\n",
    "df = df.withColumn(\"dlat\", col(\"lat2_rad\") - col(\"lat1_rad\")) \\\n",
    "       .withColumn(\"dlon\", col(\"lon2_rad\") - col(\"lon1_rad\"))\n",
    "\n",
    "# Aplicar a fórmula de Haversine\n",
    "df = df.withColumn(\"a\", sin(col(\"dlat\") / 2)**2 + cos(col(\"lat1_rad\")) * cos(col(\"lat2_rad\")) * sin(col(\"dlon\") / 2)**2)\n",
    "\n",
    "df = df.withColumn(\"c\", 2 * atan2(sqrt(col(\"a\")), sqrt(1 - col(\"a\"))))\n",
    "\n",
    "# Calcular a distância final\n",
    "df = df.withColumn(\"distancia_km\", col(\"c\") * R)\n",
    "\n",
    "# Selecionar as colunas de interesse\n",
    "df_final = df.select(\"latitude_loc\", \"longtitude\", \"LATITUDE_VEICULO\", \"LONGITUDE_VEICULO\", \"distancia_km\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7c793e74-701a-49de-b6b3-b7ec21618b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-------------------+-------------------+------------------+\n",
      "|latitude_loc|longtitude|   LATITUDE_VEICULO|  LONGITUDE_VEICULO|      distancia_km|\n",
      "+------------+----------+-------------------+-------------------+------------------+\n",
      "|  -46.653938|-23.523084|-46.648288333333326|-23.526863333333335|0.6912804698332657|\n",
      "|  -46.658771|-23.522696|-46.648288333333326|-23.526863333333335|1.2082377393574435|\n",
      "|  -46.664001|-23.521879|-46.648288333333326|-23.526863333333335| 1.788102844213461|\n",
      "|  -46.673287|-23.479126|-46.648288333333326|-23.526863333333335| 4.582447213466181|\n",
      "+------------+----------+-------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "43c3ad80-7da2-43d3-a5bf-c86c31d6ff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------------+----------+-----------------+---------+---------------+-------------------+-------------------+-----------------------+------------------+\n",
      "|ID_PARADA|         nome_parada|latitude_loc|longtitude|VEICULO_ACESSIVEL|TIMESTAMP|PREFIXO_VEICULO|  LONGITUDE_VEICULO|   LATITUDE_VEICULO|HORARIO_PREVISTO_CHEADA|     diff_latitude|\n",
      "+---------+--------------------+------------+----------+-----------------+---------+---------------+-------------------+-------------------+-----------------------+------------------+\n",
      "|700016473|    ANHANGUERA - C/B|  -46.653938|-23.523084|             true|     null|          11523|-46.648288333333326|-23.526863333333335|                  20:09| 3272.209692597927|\n",
      "|700013950|CAMISA VERDE E BR...|  -46.658771|-23.522696|             true|     null|          11523|-46.648288333333326|-23.526863333333335|                  20:10| 3272.209692597927|\n",
      "| 60016465|QUIRINO DOS SANTO...|  -46.664001|-23.521879|             true|     null|          11523|-46.648288333333326|-23.526863333333335|                  20:12| 3272.209692597927|\n",
      "|130001304|ENG. DIAS DE BARR...|  -46.673287|-23.479126|             true|     null|          11523|-46.648288333333326|-23.526863333333335|                  20:38|3328.0016484379967|\n",
      "+---------+--------------------+------------+----------+-----------------+---------+---------------+-------------------+-------------------+-----------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_gold_diff.withColumn(\"diff_latitude\", calc_km_long_lat(\n",
    "    col(\"latitude_loc\").cast('decimal'),\n",
    "    col(\"longtitude\").cast('decimal'),\n",
    "    col(\"LATITUDE_VEICULO\").cast('decimal'),\n",
    "    col(\"LONGITUDE_VEICULO\").cast('decimal'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c7807f80-c451-48e9-878e-039c56619c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_path_posicao_veiculo = 's3a://silver/posicao_veiculo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9f2e31f8-2626-4b59-8905-2b4b1f3bd066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posicao_veiculo = spark.read.format('delta') \\\n",
    "  .load(silver_path_posicao_veiculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "26eff556-20e6-423a-9f73-fb5625dcc78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+----------------------+---------------------+-----------------+---------------+-----------------+----------+-------------------+-------------------+\n",
      "|LETREIRO_LINHA|ID_LINHA|LETREIRO_DESTINO_LINHA|LETREIRO_ORIGEM_LINHA|QTD_VEICULO_LINHA|SENTIDO_O_LINHA|ACESSIVEL_VEICULO|ID_VEICULO|  LONGITUDE_VEICULO|   LATITUDE_VEICULO|\n",
      "+--------------+--------+----------------------+---------------------+-----------------+---------------+-----------------+----------+-------------------+-------------------+\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|         -46.674865|         -23.499823|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                5|              1|             true|     11523|         -46.667728|        -23.4743105|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|        -46.6731595|        -23.4808915|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|        -46.6731805|        -23.4805725|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|          -46.67767|        -23.4948215|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|-46.676711749999996|       -23.49650175|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|         -46.678778|         -23.493453|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                5|              1|             true|     11523|       -46.67118275|-23.477309500000004|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                5|              1|             true|     11523|        -46.6688805|        -23.4752765|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|         -46.675798|         -23.487502|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|         -46.674172|        -23.4843345|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|-46.673339999999996|         -23.482439|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                5|              1|             true|     11523|         -46.672959|        -23.4798495|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|         -46.675415|-23.489724000000002|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|-46.677738000000005|         -23.494709|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|-46.676823999999996|         -23.491877|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                5|              1|             true|     11523|       -46.66957275|      -23.475762125|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|        -46.6749935|-23.499670000000002|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|         -46.675804|        -23.4982015|\n",
      "|       9500-10|     461|       PÇA. DO CORREIO|   TERM. CACHOEIRINHA|                4|              1|             true|     11523|       -46.67501575|       -23.48583225|\n",
      "+--------------+--------+----------------------+---------------------+-----------------+---------------+-----------------+----------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_posicao_veiculo.filter(\"ID_VEICULO=11523\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d257386f-f488-4436-831c-774e8ef250bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
