{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79c0efba-9415-4c4c-aeff-a36d3c1cb6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "jdbc_driver_path = \"/util/jar/postgresql-42.5.1.jar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf471d15-053c-4314-a379-09beca89718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Escrita no PostgreSQL\") \\\n",
    "    .config(\"spark.jars\", jdbc_driver_path) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "url = \"jdbc:postgresql://db:5432/admin\"\n",
    "properties = {\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"admin\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "tabela = \"PR_VL_MD_TO_CGDA\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fcede7f-635a-4ef6-8fb6-2177143bf0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, percentile_approx\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "             .appName('lab') # Name the app\n",
    "             .config(\"hive.metastore.uris\", \"thrift://metastore:9083\") # Set external Hive Metastore\n",
    "             .config(\"hive.metastore.schema.verification\", \"false\") # Prevent some errors\n",
    "             .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "             .config('spark.sql.extensions','io.delta.sql.DeltaSparkSessionExtension') \\\n",
    "            .config('spark.sql.catalog.spark_catalog','org.apache.spark.sql.delta.catalog.DeltaCatalog') \\\n",
    "             .enableHiveSupport()\n",
    "             .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408d0c2a-582a-4764-952c-6e86165218ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|    teste|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f75270b-546c-41d4-ac8c-471357c008fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted_path_previsao_chegada = 's3a://trusted/previsao_chegada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a845da4b-1bf1-48d3-b9f4-d4abac5807cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previsao_chegada = spark.read.format('delta').load(trusted_path_previsao_chegada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f55d7d-0eda-4ced-ae41-78481fdb7d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----------------------+---------------+------------+----------+-------------------+-------------------+------------------+--------------+\n",
      "|dat_ref_carga|id_parada|horario_previsto_cheada|PREFIXO_VEICULO|latitude_loc|longtitude|   LATITUDE_VEICULO|  LONGITUDE_VEICULO|      distancia_km|diff_in_minute|\n",
      "+-------------+---------+-----------------------+---------------+------------+----------+-------------------+-------------------+------------------+--------------+\n",
      "|        20:47|360004796|                  20:53|          31943|  -46.444853|-23.513681| -46.46042166666666| -23.51553333333333|1.7369629819857777|           6.0|\n",
      "|        20:47|360004796|                  21:03|          31936|  -46.444853|-23.513681|-46.485756666666674|-23.515643333333333| 4.550762764692933|          16.0|\n",
      "|        20:47|360004796|                  21:04|          31840|  -46.444853|-23.513681|-46.490275000000004|         -23.515145| 5.051940356784393|          17.0|\n",
      "|        20:47|360004796|                  21:08|          31932|  -46.444853|-23.513681| -46.50167166666667|-23.512968333333333| 6.318183183078207|          21.0|\n",
      "|        20:47|360004796|                  21:29|          31086|  -46.444853|-23.513681| -46.56094666666666| -23.53769666666667|13.039231985971544|          42.0|\n",
      "|        20:47|360004796|                  21:29|          31229|  -46.444853|-23.513681| -46.56203666666667|-23.537944999999997|13.161900976473966|          42.0|\n",
      "|        20:47|360004796|                  21:33|          31839|  -46.444853|-23.513681| -46.57630166666666|-23.540928333333333|14.764406694922435|          46.0|\n",
      "|        20:47|360004796|                  21:42|          31931|  -46.444853|-23.513681|          -46.60569|-23.549889999999998| 18.09753319274707|          55.0|\n",
      "|        20:47|350002418|                  21:01|          31937|  -46.391151|-23.502355| -46.41938666666667|-23.494115000000004|3.2026012181605976|          14.0|\n",
      "|        20:47|350002418|                  21:03|          31847|  -46.391151|-23.502355|-46.421238333333335| -23.49425833333333| 3.402668957701603|          16.0|\n",
      "|        20:47|350002418|                  21:10|          31817|  -46.391151|-23.502355|-46.438185000000004|-23.494744999999998| 5.262380106565737|          23.0|\n",
      "|        20:47|350002418|                  21:28|          31943|  -46.391151|-23.502355| -46.46042166666666| -23.51553333333333| 7.768491364899536|          41.0|\n",
      "|        20:47|350002418|                  21:37|          31936|  -46.391151|-23.502355|-46.485756666666674|-23.515643333333333|10.568836888124252|          50.0|\n",
      "|        20:47|350002418|                  21:39|          31840|  -46.391151|-23.502355|-46.490275000000004|         -23.515145|11.065570107630375|          52.0|\n",
      "|        20:47|350002418|                  21:43|          31932|  -46.391151|-23.502355| -46.50167166666667|-23.512968333333333| 12.31621063701169|          56.0|\n",
      "|        20:47|350002418|                  22:04|          31086|  -46.391151|-23.502355| -46.56094666666666| -23.53769666666667| 19.07338863735889|          17.0|\n",
      "|        20:47|350002418|                  22:04|          31229|  -46.391151|-23.502355| -46.56203666666667|-23.537944999999997| 19.19605921873686|          17.0|\n",
      "|        20:47|350002418|                  22:08|          31839|  -46.391151|-23.502355| -46.57630166666666|-23.540928333333333|20.798565728716856|          21.0|\n",
      "|        20:47|350002418|                  22:17|          31931|  -46.391151|-23.502355|          -46.60569|-23.549889999999998| 24.13152770635595|          30.0|\n",
      "|        20:47| 80014580|                  20:52|          31931|  -46.589425|-23.543817|          -46.60569|-23.549889999999998|1.8671580884546701|           5.0|\n",
      "+-------------+---------+-----------------------+---------------+------------+----------+-------------------+-------------------+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_previsao_chegada.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6586865c-1f30-4a2c-9f37-adcc6f47e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insight_velocidade = df_previsao_chegada.withColumn(\"velocidade_para_chegar\", (col(\"distancia_km\") * 60) / col(\"diff_in_minute\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da415640-914a-44e3-a3e5-7e2cd2340204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>id_parada</th><th>media_velocidade</th></tr>\n",
       "<tr><td>1010076</td><td>191.9065847677062</td></tr>\n",
       "<tr><td>1410076</td><td>49.323195284355265</td></tr>\n",
       "<tr><td>1506163</td><td>121.39152707090088</td></tr>\n",
       "<tr><td>3514897</td><td>73.94280743889519</td></tr>\n",
       "<tr><td>4203724</td><td>105.86262687488104</td></tr>\n",
       "<tr><td>5614544</td><td>99.42775294780941</td></tr>\n",
       "<tr><td>5614560</td><td>130.09091261999896</td></tr>\n",
       "<tr><td>5614562</td><td>79.85953522343779</td></tr>\n",
       "<tr><td>6009703</td><td>243.49736473422357</td></tr>\n",
       "<tr><td>7014417</td><td>285.96742041965507</td></tr>\n",
       "<tr><td>7203285</td><td>332.5806932220917</td></tr>\n",
       "<tr><td>7608527</td><td>1107.753522180444</td></tr>\n",
       "<tr><td>8103045</td><td>47.80124121329188</td></tr>\n",
       "<tr><td>8210206</td><td>42.43319224700467</td></tr>\n",
       "<tr><td>60012951</td><td>46.60324237642069</td></tr>\n",
       "<tr><td>60016784</td><td>168.66916467373255</td></tr>\n",
       "<tr><td>70016561</td><td>48.26912592838366</td></tr>\n",
       "<tr><td>80014597</td><td>159.26654533625805</td></tr>\n",
       "<tr><td>100014589</td><td>195.55237691134352</td></tr>\n",
       "<tr><td>220015547</td><td>46.26396390987547</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+---------+------------------+\n",
       "|id_parada|  media_velocidade|\n",
       "+---------+------------------+\n",
       "|  1010076| 191.9065847677062|\n",
       "|  1410076|49.323195284355265|\n",
       "|  1506163|121.39152707090088|\n",
       "|  3514897| 73.94280743889519|\n",
       "|  4203724|105.86262687488104|\n",
       "|  5614544| 99.42775294780941|\n",
       "|  5614560|130.09091261999896|\n",
       "|  5614562| 79.85953522343779|\n",
       "|  6009703|243.49736473422357|\n",
       "|  7014417|285.96742041965507|\n",
       "|  7203285| 332.5806932220917|\n",
       "|  7608527| 1107.753522180444|\n",
       "|  8103045| 47.80124121329188|\n",
       "|  8210206| 42.43319224700467|\n",
       "| 60012951| 46.60324237642069|\n",
       "| 60016784|168.66916467373255|\n",
       "| 70016561| 48.26912592838366|\n",
       "| 80014597|159.26654533625805|\n",
       "|100014589|195.55237691134352|\n",
       "|220015547| 46.26396390987547|\n",
       "+---------+------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import percentile_approx\n",
    "df_insight_velocidade.filter(\"velocidade_para_chegar > 40\").groupBy(\"id_parada\").agg(percentile_approx(\"velocidade_para_chegar\", 0.5).alias(\"media_velocidade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d0b8fcf-0c5f-436e-8b0a-cd2ded89f968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS SPTRANS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "959288f1-bd52-41aa-a6d5-eabe01cd58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insight_velocidade.write.mode(\"overwrite\").saveAsTable(\"SPTRANS.PR_VL_MD_TO_CGDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67670e69-edf4-470f-b78f-02dd389a8307",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o213.jdbc.\n: org.postgresql.util.PSQLException: Connection to localhost:15432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)\n\tat org.postgresql.Driver.makeConnection(Driver.java:434)\n\tat org.postgresql.Driver.connect(Driver.java:291)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)\n\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:122)\n\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:118)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:50)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:363)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:757)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)\n\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)\n\tat java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)\n\tat java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)\n\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)\n\tat java.base/java.net.Socket.connect(Socket.java:633)\n\tat org.postgresql.core.PGStream.createSocket(PGStream.java:241)\n\tat org.postgresql.core.PGStream.<init>(PGStream.java:98)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)\n\t... 51 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_insight_velocidade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjdbc\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtabela\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproperties\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:1340\u001b[0m, in \u001b[0;36mDataFrameWriter.jdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m properties:\n\u001b[1;32m   1339\u001b[0m     jprop\u001b[38;5;241m.\u001b[39msetProperty(k, properties[k])\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjdbc\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjprop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o213.jdbc.\n: org.postgresql.util.PSQLException: Connection to localhost:15432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:247)\n\tat org.postgresql.Driver.makeConnection(Driver.java:434)\n\tat org.postgresql.Driver.connect(Driver.java:291)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)\n\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:122)\n\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:118)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:50)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:363)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:757)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)\n\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)\n\tat java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)\n\tat java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)\n\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)\n\tat java.base/java.net.Socket.connect(Socket.java:633)\n\tat org.postgresql.core.PGStream.createSocket(PGStream.java:241)\n\tat org.postgresql.core.PGStream.<init>(PGStream.java:98)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)\n\t... 51 more\n"
     ]
    }
   ],
   "source": [
    "df_insight_velocidade.write.jdbc(url=url, table=tabela, mode=\"overwrite\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba988f50-91cd-4ddb-b49d-8b3b22a7e104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
